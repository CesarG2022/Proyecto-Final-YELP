{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/probando/review_2018.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.info()\n",
        "# Selecciona todas las columnas para las filas con índices entre 0 y 10\n",
        "df = df.iloc[:100]\n",
        "#We add a blank space before each review, because I didn't want to convert the first word of each review\n",
        "df.text = ' '+df.text\n",
        "#capitalize(): to change the first letter from a word to lowercase\n",
        "#strip(): to remove empty spaces from the left and right\n",
        "df.text = df.text.str.capitalize().str.strip()\n",
        "#df['text'] = df['text'].astype('string')\n",
        "# df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoYHdoERbeqy",
        "outputId": "7865dff8-bd77-4625-9cdb-e59d68f3d9ca"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 906362 entries, 0 to 906361\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count   Dtype         \n",
            "---  ------       --------------   -----         \n",
            " 0   review_id    906362 non-null  object        \n",
            " 1   user_id      906362 non-null  object        \n",
            " 2   business_id  906362 non-null  object        \n",
            " 3   stars        906362 non-null  int64         \n",
            " 4   useful       906362 non-null  int64         \n",
            " 5   funny        906362 non-null  int64         \n",
            " 6   cool         906362 non-null  int64         \n",
            " 7   text         906362 non-null  object        \n",
            " 8   date         906362 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), int64(4), object(4)\n",
            "memory usage: 62.2+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[name] = value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenización"
      ],
      "metadata": {
        "id": "e87srH8AOMV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('word_tokenize')\n",
        "nltk.download('punkt')\n",
        "# importing libraries\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "import nltk.data\n",
        "set(stopwords.words('english'))\n",
        "# set of stop words\n",
        "stop_words = set(stopwords.words('english')) \n",
        "# word_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9gSqIE1no-y",
        "outputId": "729d6efa-2cb3-4813-9ce6-4ddaf9c89490"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Error loading word_tokenize: Package 'word_tokenize' not\n",
            "[nltk_data]     found in index\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def not_stopwords(frase):   \n",
        "\n",
        "# tokens of words  \n",
        "  word_tokens = word_tokenize(frase) \n",
        "\n",
        "  filtered_sentence = [] \n",
        "\n",
        "  for w in word_tokens: \n",
        "      if w not in stop_words: \n",
        "          filtered_sentence.append(w) \n",
        "\n",
        "  return \" \".join(filtered_sentence) "
      ],
      "metadata": {
        "id": "1r-PZ2g7Q3-w"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df.text.apply(lambda x: not_stopwords(x))\n",
        "df.text.iloc[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JY6ZzRXvKCzH",
        "outputId": "a6bf2b18-686b-4c6f-eb7f-7a37be36a005"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"boyfriend tried deli first time today . turkey , avocado & bacon panini ha buffalo chicken wrap . definitely returning . wait food n't long , always appreciated lunch hour . much choose . salads , soup , macaroni , sandwiches hot food . love deli many options choose !\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #filtrar caracteres especiales dentro de un dataframe con la libreria re en python\n",
        "import re\n",
        "df.text = df.text.apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",str(x)))\n",
        "# now\n",
        "print(df.text.loc[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwc_JS2faCvE",
        "outputId": "95c4cc49-7e34-44f6-92d7-c0649fc2368c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boyfriend tried deli first time today   turkey   avocado   bacon panini ha buffalo chicken wrap   definitely returning   wait food n t long   always appreciated lunch hour   much choose   salads   soup   macaroni   sandwiches hot food   love deli many options choose  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FreqDist: Cuantas veces se repite por review"
      ],
      "metadata": {
        "id": "ezy9BSDSC81R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df.text.apply(lambda x: word_tokenize(x))\n",
        "df.text\n",
        "import nltk\n",
        "df.text = df.text.apply(lambda x: nltk.FreqDist(x))\n",
        "df.text"
      ],
      "metadata": {
        "id": "DNMQEqPrbtiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82516e6-c413-49d1-994f-0ede810b993c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     {'decide': 1, 'eat': 1, 'aware': 1, 'going': 1...\n",
              "1     {'really': 1, 'stars': 1, 'one': 2, 'love': 1,...\n",
              "2     {'boyfriend': 1, 'tried': 1, 'deli': 2, 'first...\n",
              "3     {'amazing': 1, 'biscuits': 1, 'fill': 1, 'blan...\n",
              "4     {'cafe': 1, 'extremely': 1, 'cute': 1, 'came':...\n",
              "                            ...                        \n",
              "95    {'ve': 1, 'times': 1, 'n': 1, 't': 1, 'disappo...\n",
              "96    {'place': 2, 'searching': 1, 'friend': 1, 'tri...\n",
              "97    {'unique': 1, 'professional': 1, 'based': 2, '...\n",
              "98    {'top': 2, 'notch': 2, 'street': 1, 'tacos': 1...\n",
              "99    {'holy': 1, 'bat': 1, 'crap': 1, 'place': 2, '...\n",
              "Name: text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemmer"
      ],
      "metadata": {
        "id": "lyflJ-iOJL5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def stemmering(phrase):\n",
        "  Stem_words = []\n",
        "  ps =PorterStemmer()\n",
        "  for w in phrase:\n",
        "      rootWord=ps.stem(w)\n",
        "      Stem_words.append(rootWord)\n",
        "  return Stem_words"
      ],
      "metadata": {
        "id": "NHvnvdMoC0LZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text = df.text.apply(lambda x: stemmering(x))\n",
        "df.text "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqCfubYmHHBh",
        "outputId": "126eb8b7-ff63-4d90-a731-bb341d63726e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [long, usual, decid, eat, awar, go, take, hour...\n",
              "1     [sushi, th, street, good, peopl, one, area, or...\n",
              "2     [deli, food, choos, boyfriend, tri, first, tim...\n",
              "3     [amaz, biscuit, fill, blank, great, cocktail, ...\n",
              "4     [breakfast, cafe, extrem, cute, came, am, even...\n",
              "                            ...                        \n",
              "95    [ve, time, n, t, disappoint, yet, meat, eater,...\n",
              "96    [place, want, search, friend, tri, sever, nail...\n",
              "97    [base, experi, highest, uniqu, profession, ope...\n",
              "98    [top, notch, made, street, taco, great, servic...\n",
              "99    [place, holi, bat, crap, amaz, go, st, pete, a...\n",
              "Name: text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}